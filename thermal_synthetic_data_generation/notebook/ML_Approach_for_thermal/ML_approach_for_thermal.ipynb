{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 (ML Variant - Offline Training): This script uses the historical synthetic data (CSV), land cover map, and the previously generated probability map (.npy) to train an ML model that learns to predict the thermal probability based on context. It then saves the trained model.  \n",
    "\n",
    "#     Phase 2 (ML Variant - Online Inference): This script runs on the simulated UAV. It loads the trained ML model and uses the UAV's real-time context (position, time, land cover) to predict thermal probability. If the probability is high enough, it triggers the instantiation of average thermal metrics (loaded from the .npz file generated by the original Phase 1 script).\n",
    "\n",
    "# Assumptions Made:\n",
    "\n",
    "#     We will train the ML model to predict the thermal presence probability calculated by the original Phase 1 script (i.e., using the values in conditional_probability_map.npy as the target variable). This turns it into a regression problem.\n",
    "#     We will use a RandomForestRegressor from scikit-learn as an example model. You might substitute other models (like XGBoost, LightGBM, or Neural Networks).\n",
    "#     Basic feature engineering is used (e.g., using coordinates and context indices directly). More advanced feature engineering might improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script 1: Phase 1 - Offline ML Model Training -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "import pyproj\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.ops import transform as shapely_transform\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib # For saving the model\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\synthetic_thermal_data_5yr_landcover_name.csv\" # INPUT: Synthetic Data\n",
    "GEOJSON_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\df.geojson\" # INPUT: Boundaries (for context)\n",
    "LAND_COVER_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\dataset\\landcover-2020-classification.tif\" # INPUT: Land Cover\n",
    "METADATA_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\probability_map_metadata.json\" # INPUT: Metadata from original Phase 1\n",
    "PROB_MAP_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\conditional_probability_map.npy\" # INPUT: Target probabilities\n",
    "\n",
    "OUTPUT_FOLDER = r\"C:\\work\\ETS_mirza\\distributed_montreal\"\n",
    "MODEL_FILENAME = \"thermal_predictor_rf_model.joblib\" # OUTPUT: Trained Model\n",
    "MODEL_METADATA_FILENAME = \"thermal_predictor_rf_metadata.json\" # OUTPUT: Info about model features\n",
    "\n",
    "# --- Load Metadata (Needed for context mapping and grid info) ---\n",
    "print(f\"Loading metadata from: {METADATA_PATH}\")\n",
    "try:\n",
    "    with open(METADATA_PATH, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    grid_crs_str = metadata['grid_crs']\n",
    "    grid_affine = rasterio.Affine.from_gdal(*metadata['grid_affine_transform_gdal'])\n",
    "    source_crs_geojson = metadata['grid_origin_in_geojson_crs']['crs']\n",
    "    season_map = metadata['context_mappings']['season']\n",
    "    tod_map = metadata['context_mappings']['time_of_day']\n",
    "    lc_code_to_idx_map = {int(k):v for k,v in metadata['context_mappings']['land_cover_code_to_index'].items()}\n",
    "    # Also load grid dimensions needed for matching target Y\n",
    "    grid_height = metadata['grid_dimensions']['height']\n",
    "    grid_width = metadata['grid_dimensions']['width']\n",
    "    num_season_cats = len(season_map)\n",
    "    num_tod_cats = len(tod_map)\n",
    "    num_lc_cats = len(lc_code_to_idx_map)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing metadata JSON file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Target Probabilities ---\n",
    "print(f\"Loading target probability map from: {PROB_MAP_PATH}\")\n",
    "try:\n",
    "    prob_map_target = np.load(PROB_MAP_PATH)\n",
    "    # Verify shape matches metadata\n",
    "    if prob_map_target.shape != tuple(metadata['probability_map_shape']):\n",
    "         print(f\"ERROR: Loaded probability map shape {prob_map_target.shape} != metadata shape {metadata['probability_map_shape']}\")\n",
    "         exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading probability map NumPy file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Synthetic Data for Features (X) ---\n",
    "print(f\"Loading synthetic data for features from: {CSV_PATH}\")\n",
    "try:\n",
    "    thermal_df = pd.read_csv(CSV_PATH, parse_dates=['timestamp_utc'])\n",
    "    required_cols = ['easting', 'northing', 'land_cover_type'] # Need these for features/target lookup\n",
    "    thermal_df.dropna(subset=required_cols, inplace=True)\n",
    "\n",
    "    # Recreate necessary context indices and raster coordinates\n",
    "    land_cover_names_inv = { # Should match Phase 1 generation script\n",
    "        \"Needleleaf Forest\": 1, \"Taiga Forest\": 2, \"Broadleaf Forest\": 5, \"Mixed Forest\": 6,\n",
    "        \"Shrubland\": 8, \"Grassland\": 10, \"Shrubland-Lichen-Moss\": 11, \"Grassland-Lichen-Moss\": 12,\n",
    "        \"Barren-Lichen-Moss\": 13, \"Wetland\": 14, \"Cropland\": 15, \"Barren lands\": 16,\n",
    "        \"Urban\": 17, \"Water\": 18, \"Snow/Ice\": 19, \"NoData\": 0, \"Unknown\": 0\n",
    "    }\n",
    "    default_lc_code = 0\n",
    "    thermal_df['land_cover_code'] = thermal_df['land_cover_type'].apply(lambda x: land_cover_names_inv.get(x, default_lc_code))\n",
    "\n",
    "    # Helper functions to get indices\n",
    "    def get_season_idx(month):\n",
    "        if month in [6, 7, 8]: return season_map[\"Summer\"]\n",
    "        if month in [5, 9]: return season_map[\"Spring/Fall\"]\n",
    "        return None\n",
    "    def get_tod_idx(hour):\n",
    "        if 10 <= hour < 12: return time_of_day_map[\"Morning\"]\n",
    "        if 12 <= hour < 16: return time_of_day_map[\"Afternoon\"]\n",
    "        if 16 <= hour < 18: return time_of_day_map[\"Late Afternoon\"]\n",
    "        return None\n",
    "\n",
    "    thermal_df['season_idx'] = thermal_df['timestamp_utc'].dt.month.apply(get_season_idx)\n",
    "    thermal_df['tod_idx'] = thermal_df['timestamp_utc'].dt.hour.apply(get_tod_idx)\n",
    "    thermal_df['lc_idx'] = thermal_df['land_cover_code'].apply(lambda x: lc_code_to_idx_map.get(x))\n",
    "\n",
    "    # Filter out rows where context is invalid (outside defined time/season/lc)\n",
    "    thermal_df.dropna(subset=['season_idx', 'tod_idx', 'lc_idx'], inplace=True)\n",
    "    thermal_df['season_idx'] = thermal_df['season_idx'].astype(int)\n",
    "    thermal_df['tod_idx'] = thermal_df['tod_idx'].astype(int)\n",
    "    thermal_df['lc_idx'] = thermal_df['lc_idx'].astype(int)\n",
    "\n",
    "    # Need coordinates in Raster CRS for grid lookup\n",
    "    transform_geojson_to_raster = None\n",
    "    if source_crs_raster != source_crs_geojson:\n",
    "        transformer_g2r = pyproj.Transformer.from_crs(source_crs_geojson, source_crs_raster, always_xy=True)\n",
    "        transform_geojson_to_raster = transformer_g2r.transform\n",
    "    else:\n",
    "        transform_geojson_to_raster = lambda x, y: (x, y) # Identity transform\n",
    "\n",
    "    coords_raster = [transform_geojson_to_raster(x, y) for x, y in zip(thermal_df['easting'], thermal_df['northing'])]\n",
    "    thermal_df['easting_raster'] = [c[0] for c in coords_raster]\n",
    "    thermal_df['northing_raster'] = [c[1] for c in coords_raster]\n",
    "\n",
    "    # Get grid indices\n",
    "    rows, cols = rasterio.transform.rowcol(grid_affine, thermal_df['easting_raster'], thermal_df['northing_raster'])\n",
    "    thermal_df['grid_row'] = rows\n",
    "    thermal_df['grid_col'] = cols\n",
    "\n",
    "    # Filter points outside the defined grid\n",
    "    valid_grid = (thermal_df['grid_row'] >= 0) & (thermal_df['grid_row'] < grid_height) & \\\n",
    "                 (thermal_df['grid_col'] >= 0) & (thermal_df['grid_col'] < grid_width)\n",
    "    thermal_df = thermal_df[valid_grid].copy()\n",
    "\n",
    "    print(f\"Prepared {len(thermal_df)} valid events for training features.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing CSV for training: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Feature Engineering (Create X) ---\n",
    "print(\"Creating feature set (X)...\")\n",
    "# Select features: Location (raster CRS), Time contexts, Land Cover context\n",
    "# Consider adding cyclical time features for better learning\n",
    "# Example: Add sin/cos of day of year and time of day\n",
    "day_of_year = thermal_df['timestamp_utc'].dt.dayofyear\n",
    "seconds_in_day = thermal_df['timestamp_utc'].dt.hour * 3600 + \\\n",
    "                 thermal_df['timestamp_utc'].dt.minute * 60 + \\\n",
    "                 thermal_df['timestamp_utc'].dt.second\n",
    "\n",
    "thermal_df['day_sin'] = np.sin(2 * np.pi * day_of_year / 365.0)\n",
    "thermal_df['day_cos'] = np.cos(2 * np.pi * day_of_year / 365.0)\n",
    "thermal_df['time_sin'] = np.sin(2 * np.pi * seconds_in_day / (24.0 * 3600.0))\n",
    "thermal_df['time_cos'] = np.cos(2 * np.pi * seconds_in_day / (24.0 * 3600.0))\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = ['easting_raster', 'northing_raster',\n",
    "                'season_idx', 'tod_idx', 'lc_idx',\n",
    "                'day_sin', 'day_cos', 'time_sin', 'time_cos']\n",
    "X = thermal_df[feature_cols].values\n",
    "print(f\"Feature set X created with shape: {X.shape}\")\n",
    "\n",
    "# --- Target Definition (Create Y) ---\n",
    "print(\"Creating target variable (Y) from probability map...\")\n",
    "# Lookup the probability from the loaded map using the calculated indices\n",
    "y_indices = thermal_df['grid_row'].values\n",
    "x_indices = thermal_df['grid_col'].values\n",
    "s_indices = thermal_df['season_idx'].values\n",
    "t_indices = thermal_df['tod_idx'].values\n",
    "l_indices = thermal_df['lc_idx'].values\n",
    "\n",
    "try:\n",
    "    Y = prob_map_target[y_indices, x_indices, s_indices, t_indices, l_indices]\n",
    "    print(f\"Target variable Y created with shape: {Y.shape}\")\n",
    "except IndexError as e:\n",
    "    print(f\"Error looking up target values in probability map: {e}\")\n",
    "    print(\"Check consistency between CSV event contexts and probability map dimensions/indices.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "     print(f\"Unexpected error creating target Y: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# --- Model Training ---\n",
    "# Using RandomForestRegressor as an example\n",
    "print(\"Training RandomForestRegressor model...\")\n",
    "# Adjust n_estimators, max_depth etc. for performance/speed\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "start_train_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_train_time = time.time()\n",
    "print(f\"Model training finished in {end_train_time - start_train_time:.2f} seconds.\")\n",
    "\n",
    "# --- Evaluation (Optional but Recommended) ---\n",
    "print(\"Evaluating model on test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test Set Mean Squared Error (MSE): {mse:.4g}\")\n",
    "print(f\"Test Set R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "# --- Save Model and Feature Info ---\n",
    "model_output_path = os.path.join(OUTPUT_FOLDER, MODEL_FILENAME)\n",
    "model_metadata_output_path = os.path.join(OUTPUT_FOLDER, MODEL_METADATA_FILENAME)\n",
    "\n",
    "print(f\"Saving trained model to: {model_output_path}\")\n",
    "try:\n",
    "    joblib.dump(model, model_output_path)\n",
    "    print(\"Model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "\n",
    "model_metadata = {\n",
    "    \"description\": \"Trained RandomForestRegressor model for predicting P(Thermal|Context)\",\n",
    "    \"model_file\": MODEL_FILENAME,\n",
    "    \"source_synthetic_data\": CSV_PATH,\n",
    "    \"target_probability_map\": PROB_MAP_PATH,\n",
    "    \"features\": feature_cols,\n",
    "    \"training_timestamp\": datetime.now().isoformat(),\n",
    "    \"evaluation_metrics\": {\"mse\": mse, \"r2\": r2}\n",
    "}\n",
    "\n",
    "print(f\"Saving model metadata to: {model_metadata_output_path}\")\n",
    "try:\n",
    "    with open(model_metadata_output_path, 'w') as f:\n",
    "        json.dump(model_metadata, f, indent=4)\n",
    "    print(\"Model metadata saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model metadata: {e}\")\n",
    "\n",
    "print(\"\\nML Model Training (Phase 1 - ML Variant) finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Script 2: Phase 2 - Online ML Inference Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.transform import rowcol\n",
    "import pyproj\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.ops import transform as shapely_transform\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import warnings\n",
    "import joblib # For loading model\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_FOLDER = r\"C:\\work\\ETS_mirza\\distributed_montreal\"\n",
    "AVG_METRICS_MAP_FILENAME = \"average_thermal_metrics.npz\" # INPUT: Avg Metrics from original Phase 1\n",
    "METADATA_FILENAME = \"probability_map_metadata.json\" # INPUT: Metadata from original Phase 1\n",
    "LAND_COVER_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\dataset\\landcover-2020-classification.tif\" # INPUT: Land Cover Map\n",
    "REAL_TIME_CSV_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\real_time.csv\" # INPUT: Flight data\n",
    "MODEL_FILENAME = \"thermal_predictor_rf_model.joblib\" # INPUT: Trained ML Model\n",
    "MODEL_METADATA_FILENAME = \"thermal_predictor_rf_metadata.json\" # INPUT: Model Feature Info\n",
    "\n",
    "OUTPUT_CSV_FILENAME = \"phase2_estimation_output_ml.csv\" # OUTPUT: Results\n",
    "\n",
    "# --- Parameters ---\n",
    "PROBABILITY_THRESHOLD = 0.5 # Example threshold for ML model output\n",
    "ENERGY_NEED_THRESHOLD = 80 # Example battery threshold\n",
    "\n",
    "# --- Load Metadata and Maps ---\n",
    "METADATA_PATH = os.path.join(OUTPUT_FOLDER, METADATA_FILENAME)\n",
    "AVG_METRICS_MAP_PATH = os.path.join(OUTPUT_FOLDER, AVG_METRICS_MAP_FILENAME)\n",
    "MODEL_PATH = os.path.join(OUTPUT_FOLDER, MODEL_FILENAME)\n",
    "MODEL_METADATA_PATH = os.path.join(OUTPUT_FOLDER, MODEL_METADATA_FILENAME)\n",
    "\n",
    "print(f\"Loading metadata from: {METADATA_PATH}\")\n",
    "try:\n",
    "    with open(METADATA_PATH, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    grid_crs_str = metadata['grid_crs']\n",
    "    # Need affine transform for coordinate conversions if needed by features, or LC lookup\n",
    "    grid_affine = rasterio.Affine.from_gdal(*metadata['grid_affine_transform_gdal'])\n",
    "    source_crs_geojson = metadata['grid_origin_in_geojson_crs']['crs']\n",
    "    season_map = metadata['context_mappings']['season']\n",
    "    tod_map = metadata['context_mappings']['time_of_day']\n",
    "    lc_code_to_idx_map = {int(k):v for k,v in metadata['context_mappings']['land_cover_code_to_index'].items()}\n",
    "    # Need mappings for features\n",
    "    season_map_inv = {v: k for k, v in season_map.items()}\n",
    "    tod_map_inv = {v: k for k, v in tod_map.items()}\n",
    "    lc_idx_to_code_map = {v: k for k, v in lc_code_to_idx_map.items()}\n",
    "\n",
    "except Exception as e: print(f\"Error loading metadata JSON file: {e}\"); exit()\n",
    "\n",
    "print(f\"Loading average metrics map from: {AVG_METRICS_MAP_PATH}\")\n",
    "try:\n",
    "    avg_metrics_data = np.load(AVG_METRICS_MAP_PATH)\n",
    "    # Verify keys exist\n",
    "    required_keys = ['avg_lift', 'avg_radius', 'avg_height', 'avg_duration']\n",
    "    if not all(key in avg_metrics_data for key in required_keys):\n",
    "        raise ValueError(\"Missing required keys in average metrics file.\")\n",
    "except Exception as e: print(f\"Error loading average metrics NPZ file: {e}\"); exit()\n",
    "\n",
    "print(f\"Loading Land Cover Raster: {LAND_COVER_PATH}\")\n",
    "try:\n",
    "    lc_raster = rasterio.open(LAND_COVER_PATH)\n",
    "    source_crs_raster = lc_raster.crs\n",
    "    if str(source_crs_raster) != grid_crs_str:\n",
    "         print(f\"ERROR: Land Cover CRS {source_crs_raster} must match grid CRS {grid_crs_str} from metadata!\")\n",
    "         exit()\n",
    "except Exception as e: print(f\"Error opening land cover file: {e}\"); exit()\n",
    "\n",
    "# --- Load Trained ML Model ---\n",
    "print(f\"Loading trained ML model from: {MODEL_PATH}\")\n",
    "try:\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "except Exception as e: print(f\"Error loading trained model file: {e}\"); exit()\n",
    "\n",
    "print(f\"Loading model metadata from: {MODEL_METADATA_PATH}\")\n",
    "try:\n",
    "    with open(MODEL_METADATA_PATH, 'r') as f:\n",
    "        model_metadata = json.load(f)\n",
    "    feature_cols = model_metadata['features'] # Get feature names used during training\n",
    "except Exception as e: print(f\"Error loading model metadata: {e}\"); exit()\n",
    "\n",
    "\n",
    "# --- Setup CRS Transformations ---\n",
    "transform_geojson_to_raster = None\n",
    "transformer_g2r = None\n",
    "if source_crs_raster != source_crs_geojson:\n",
    "    try:\n",
    "        transformer_g2r = pyproj.Transformer.from_crs(source_crs_geojson, source_crs_raster, always_xy=True)\n",
    "        transform_geojson_to_raster = transformer_g2r.transform\n",
    "    except Exception as e: print(f\"Error setting up transformer: {e}\"); exit()\n",
    "else:\n",
    "     transform_geojson_to_raster = lambda x, y: (x, y) # Identity\n",
    "\n",
    "# --- Load Real-Time Flight Data ---\n",
    "print(f\"Loading flight data from: {REAL_TIME_CSV_PATH}\")\n",
    "try:\n",
    "    flight_df = pd.read_csv(REAL_TIME_CSV_PATH, parse_dates=['timestamp_utc'])\n",
    "    flight_df.sort_values(by='timestamp_utc', inplace=True)\n",
    "    # Convert Lat/Lon to projected CRS used for features (Raster CRS)\n",
    "    flight_gdf = gpd.GeoDataFrame(\n",
    "        flight_df, geometry=gpd.points_from_xy(flight_df.longitude, flight_df.latitude), crs=\"EPSG:4326\"\n",
    "    )\n",
    "    flight_gdf = flight_gdf.to_crs(grid_crs_str) # Convert to Raster CRS\n",
    "    flight_gdf['easting_raster'] = flight_gdf.geometry.x\n",
    "    flight_gdf['northing_raster'] = flight_gdf.geometry.y\n",
    "    print(f\"Loaded and transformed {len(flight_gdf)} flight data points.\")\n",
    "except Exception as e: print(f\"Error loading/processing real-time CSV: {e}\"); exit()\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_season_idx(month):\n",
    "    if month in [6, 7, 8]: return season_map[\"Summer\"]\n",
    "    if month in [5, 9]: return season_map[\"Spring/Fall\"]\n",
    "    return None\n",
    "\n",
    "def get_tod_idx(hour):\n",
    "    if 10 <= hour < 12: return time_of_day_map[\"Morning\"]\n",
    "    if 12 <= hour < 16: return time_of_day_map[\"Afternoon\"]\n",
    "    if 16 <= hour < 18: return time_of_day_map[\"Late Afternoon\"]\n",
    "    return None\n",
    "\n",
    "# --- Phase 2 Simulation Loop ---\n",
    "print(\"Starting Phase 2: Real-time ML estimation simulation...\")\n",
    "start_process_time = time.time()\n",
    "results = []\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "\n",
    "for index, row in flight_gdf.iterrows():\n",
    "    current_time = row['timestamp_utc']\n",
    "    current_easting = row['easting_raster']\n",
    "    current_northing = row['northing_raster']\n",
    "    current_battery = row['battery_percent'] # Assumed column name\n",
    "\n",
    "    # Determine Context Features\n",
    "    season_idx = get_season_idx(current_time.month)\n",
    "    tod_idx = get_tod_idx(current_time.hour)\n",
    "\n",
    "    if season_idx is None or tod_idx is None: # Skip if outside valid time\n",
    "        results.append({\"timestamp_utc\": current_time, \"ML_detected\": False, \"comment\": \"Outside active time\"})\n",
    "        continue\n",
    "\n",
    "    # Lookup Land Cover Code\n",
    "    try:\n",
    "        lc_code_gen = lc_raster.sample([(current_easting, current_northing)], indexes=1)\n",
    "        lc_code = next(lc_code_gen)[0]\n",
    "        if lc_code == lc_raster.nodata: lc_code = 0\n",
    "        lc_idx = lc_code_to_idx_map.get(lc_code)\n",
    "        if lc_idx is None: lc_idx = lc_code_to_idx_map.get(0) # Default to NoData index if code invalid\n",
    "    except Exception as e:\n",
    "        results.append({\"timestamp_utc\": current_time, \"ML_detected\": False, \"error\": f\"LC Lookup Error: {e}\"})\n",
    "        continue\n",
    "\n",
    "    # Construct Feature Vector (matching training order)\n",
    "    try:\n",
    "        day_of_year = current_time.dayofyear\n",
    "        seconds_in_day = current_time.hour * 3600 + current_time.minute * 60 + current_time.second\n",
    "        day_sin = np.sin(2 * np.pi * day_of_year / 365.0)\n",
    "        day_cos = np.cos(2 * np.pi * day_of_year / 365.0)\n",
    "        time_sin = np.sin(2 * np.pi * seconds_in_day / (24.0 * 3600.0))\n",
    "        time_cos = np.cos(2 * np.pi * seconds_in_day / (24.0 * 3600.0))\n",
    "\n",
    "        # Ensure order matches 'feature_cols' saved in model metadata\n",
    "        feature_vector = np.array([[\n",
    "            current_easting, current_northing,\n",
    "            season_idx, tod_idx, lc_idx,\n",
    "            day_sin, day_cos, time_sin, time_cos\n",
    "        ]]) # Model expects 2D array\n",
    "    except Exception as e:\n",
    "        results.append({\"timestamp_utc\": current_time, \"ML_detected\": False, \"error\": f\"Feature vector error: {e}\"})\n",
    "        continue\n",
    "\n",
    "    # Predict Probability using loaded model\n",
    "    try:\n",
    "        predicted_prob = model.predict(feature_vector)[0] # Get single prediction\n",
    "    except Exception as e:\n",
    "         results.append({\"timestamp_utc\": current_time, \"ML_detected\": False, \"error\": f\"Model prediction error: {e}\"})\n",
    "         continue\n",
    "\n",
    "    # Apply Decision Logic\n",
    "    thermal_detected = False\n",
    "    avg_metrics_output = {}\n",
    "    needs_energy = current_battery < ENERGY_NEED_THRESHOLD\n",
    "    high_prob = predicted_prob > PROBABILITY_THRESHOLD\n",
    "\n",
    "    if needs_energy and high_prob:\n",
    "        thermal_detected = True\n",
    "        # Lookup Average Metrics using the same context indices\n",
    "        try:\n",
    "            # Get grid indices for metrics map lookup\n",
    "            row_idx, col_idx = rasterio.transform.rowcol(grid_affine, current_easting, current_northing)\n",
    "            if 0 <= row_idx < avg_metrics_data['avg_lift'].shape[0] and 0 <= col_idx < avg_metrics_data['avg_lift'].shape[1]:\n",
    "                 metrics_indices = (row_idx, col_idx, season_idx, tod_idx, lc_idx)\n",
    "                 avg_lift = avg_metrics_data['avg_lift'][metrics_indices]\n",
    "                 avg_radius = avg_metrics_data['avg_radius'][metrics_indices]\n",
    "                 avg_height = avg_metrics_data['avg_height'][metrics_indices]\n",
    "                 avg_duration = avg_metrics_data['avg_duration'][metrics_indices]\n",
    "\n",
    "                 avg_metrics_output = {\n",
    "                     \"avg_lift_mps\": avg_lift if not np.isnan(avg_lift) else None,\n",
    "                     \"avg_radius_m\": avg_radius if not np.isnan(avg_radius) else None,\n",
    "                     \"avg_height_m_agl\": avg_height if not np.isnan(avg_height) else None,\n",
    "                     \"avg_duration_min\": avg_duration if not np.isnan(avg_duration) else None,\n",
    "                 }\n",
    "            else:\n",
    "                 thermal_detected = False # Grid index invalid for metrics map\n",
    "                 avg_metrics_output = {\"error\": \"Outside metrics grid\"}\n",
    "\n",
    "        except IndexError:\n",
    "             thermal_detected = False # Index error during metrics lookup\n",
    "             avg_metrics_output = {\"error\": \"Metrics lookup index error\"}\n",
    "        except Exception as e:\n",
    "             thermal_detected = False\n",
    "             avg_metrics_output = {\"error\": f\"Metrics lookup error: {e}\"}\n",
    "\n",
    "    # Store results\n",
    "    result_row = {\n",
    "        \"timestamp_utc\": current_time,\n",
    "        \"uav_lat\": row['latitude'],\n",
    "        \"uav_lon\": row['longitude'],\n",
    "        \"uav_alt_msl\": row['altitude_msl'],\n",
    "        \"uav_battery_percent\": current_battery,\n",
    "        \"needs_energy\": needs_energy,\n",
    "        \"ML_predicted_prob\": predicted_prob,\n",
    "        \"prob_threshold\": PROBABILITY_THRESHOLD,\n",
    "        \"ML_detected\": thermal_detected,\n",
    "        # Add location info for context\n",
    "        \"easting_raster\": current_easting,\n",
    "        \"northing_raster\": current_northing,\n",
    "        \"land_cover_code\": lc_code_to_idx_map.get(lc_idx, -1)\n",
    "    }\n",
    "    if thermal_detected:\n",
    "        result_row.update(avg_metrics_output)\n",
    "\n",
    "    results.append(result_row)\n",
    "\n",
    "    if (index + 1) % 500 == 0:\n",
    "        print(f\"  Processed {index+1}/{len(flight_gdf)} flight data points...\")\n",
    "\n",
    "\n",
    "print(f\"Finished processing {len(flight_gdf)} flight data points.\")\n",
    "end_process_time = time.time()\n",
    "print(f\"Processing took {end_process_time - start_process_time:.2f} seconds.\")\n",
    "\n",
    "# --- Save Output CSV ---\n",
    "if results:\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_CSV_FILENAME)\n",
    "    print(f\"Saving estimation results to: {output_path}\")\n",
    "    try:\n",
    "        output_df.to_csv(output_path, index=False, float_format='%.6g')\n",
    "        print(\"Save successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output CSV: {e}\")\n",
    "else:\n",
    "    print(\"No results generated.\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "lc_raster.close()\n",
    "warnings.resetwarnings()\n",
    "print(\"Script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_montreal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
