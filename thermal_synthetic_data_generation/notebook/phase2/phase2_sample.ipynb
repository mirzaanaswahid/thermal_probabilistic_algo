{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.transform import rowcol\n",
    "import pyproj\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.ops import transform as shapely_transform\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_FOLDER = r\"C:\\work\\ETS_mirza\\distributed_montreal\"\n",
    "METADATA_FILENAME = \"probability_map_metadata.json\"\n",
    "PROB_MAP_FILENAME = \"conditional_probability_map.npy\"\n",
    "AVG_METRICS_MAP_FILENAME = \"average_thermal_metrics.npz\"\n",
    "LAND_COVER_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\dataset\\landcover-2020-classification.tif\"\n",
    "REAL_TIME_CSV_PATH = r\"C:\\work\\ETS_mirza\\distributed_montreal\\real_time.csv\" # Assumed input file\n",
    "OUTPUT_CSV_FILENAME = \"phase2_estimation_output_mc.csv\"\n",
    "\n",
    "# --- Parameters ---\n",
    "PROBABILITY_THRESHOLD = 0.5 # Example: Minimum P(Thermal|Context) to trigger metric lookup\n",
    "ENERGY_NEED_THRESHOLD = 80 # Example: Battery % below which soaring is considered\n",
    "MC_SAMPLES = 100 # Number of random samples per estimation cycle\n",
    "AOI_SIZE_Meters = 500 # Search area radius or half-width around UAV (in meters)\n",
    "\n",
    "# --- Load Metadata and Maps ---\n",
    "METADATA_PATH = os.path.join(OUTPUT_FOLDER, METADATA_FILENAME)\n",
    "PROB_MAP_PATH = os.path.join(OUTPUT_FOLDER, PROB_MAP_FILENAME)\n",
    "AVG_METRICS_MAP_PATH = os.path.join(OUTPUT_FOLDER, AVG_METRICS_MAP_FILENAME)\n",
    "\n",
    "print(f\"Loading metadata from: {METADATA_PATH}\")\n",
    "try:\n",
    "    with open(METADATA_PATH, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    grid_crs_str = metadata['grid_crs']\n",
    "    grid_height = metadata['grid_dimensions']['height']\n",
    "    grid_width = metadata['grid_dimensions']['width']\n",
    "    grid_affine = rasterio.Affine.from_gdal(*metadata['grid_affine_transform_gdal'])\n",
    "    grid_resolution = metadata['grid_resolution']\n",
    "    map_shape = tuple(metadata['probability_map_shape'])\n",
    "    avg_metrics_shape = tuple(metadata['average_metrics_map_shape'])\n",
    "    season_map = metadata['context_mappings']['season']\n",
    "    tod_map = metadata['context_mappings']['time_of_day']\n",
    "    lc_code_to_idx_map = {int(k):v for k,v in metadata['context_mappings']['land_cover_code_to_index'].items()} # Ensure keys are int\n",
    "    season_map_inv = {v: k for k, v in season_map.items()}\n",
    "    tod_map_inv = {v: k for k, v in tod_map.items()}\n",
    "    lc_idx_to_code_map = {v: k for k, v in lc_code_to_idx_map.items()}\n",
    "    land_cover_names_map = { # Reconstruct based on expected metadata/previous script\n",
    "        1: \"Needleleaf Forest\", 2: \"Taiga Forest\", 5: \"Broadleaf Forest\", 6: \"Mixed Forest\",\n",
    "        8: \"Shrubland\", 10: \"Grassland\", 11: \"Shrubland-Lichen-Moss\", 12: \"Grassland-Lichen-Moss\",\n",
    "        13: \"Barren-Lichen-Moss\", 14: \"Wetland\", 15: \"Cropland\", 16: \"Barren lands\",\n",
    "        17: \"Urban\", 18: \"Water\", 19: \"Snow/Ice\", 0: \"NoData\", \"Unknown\": 0\n",
    "    }\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing metadata JSON file: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading probability map from: {PROB_MAP_PATH}\")\n",
    "try:\n",
    "    prob_map = np.load(PROB_MAP_PATH)\n",
    "    if tuple(map_shape) != prob_map.shape:\n",
    "        print(f\"Warning: Prob map shape {prob_map.shape} differs from metadata {map_shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading probability map NumPy file: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading average metrics map from: {AVG_METRICS_MAP_PATH}\")\n",
    "try:\n",
    "    avg_metrics_data = np.load(AVG_METRICS_MAP_PATH)\n",
    "    if tuple(avg_metrics_shape) != avg_metrics_data['avg_lift'].shape: # Check one metric shape\n",
    "         print(f\"Warning: Avg metrics map shape differs from metadata\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading average metrics NPZ file: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading Land Cover Raster: {LAND_COVER_PATH}\")\n",
    "try:\n",
    "    lc_raster = rasterio.open(LAND_COVER_PATH)\n",
    "    source_crs_raster = lc_raster.crs\n",
    "    if str(source_crs_raster) != grid_crs_str: # Check CRS consistency\n",
    "         print(f\"ERROR: Land Cover CRS {source_crs_raster} does not match grid CRS {grid_crs_str} from metadata!\")\n",
    "         exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error opening land cover file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Real-Time Flight Data ---\n",
    "print(f\"Loading flight data from: {REAL_TIME_CSV_PATH}\")\n",
    "try:\n",
    "    flight_df = pd.read_csv(REAL_TIME_CSV_PATH, parse_dates=['timestamp_utc'])\n",
    "    flight_df.sort_values(by='timestamp_utc', inplace=True)\n",
    "    # Convert Lat/Lon to GeoDataFrame to handle CRS easily\n",
    "    flight_gdf = gpd.GeoDataFrame(\n",
    "        flight_df, geometry=gpd.points_from_xy(flight_df.longitude, flight_df.latitude), crs=\"EPSG:4326\" # Assume WGS84 input\n",
    "    )\n",
    "    # Transform flight path coordinates to the grid's CRS\n",
    "    print(f\"Transforming flight path coordinates to {grid_crs_str}...\")\n",
    "    flight_gdf = flight_gdf.to_crs(grid_crs_str)\n",
    "    flight_gdf['easting_grid'] = flight_gdf.geometry.x\n",
    "    flight_gdf['northing_grid'] = flight_gdf.geometry.y\n",
    "    print(f\"Loaded and transformed {len(flight_gdf)} flight data points.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing real-time CSV file: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_season_idx(month):\n",
    "    if month in [6, 7, 8]: return season_map[\"Summer\"]\n",
    "    if month in [5, 9]: return season_map[\"Spring/Fall\"]\n",
    "    return None\n",
    "\n",
    "def get_tod_idx(hour):\n",
    "    if 10 <= hour < 12: return time_of_day_map[\"Morning\"]\n",
    "    if 12 <= hour < 16: return time_of_day_map[\"Afternoon\"]\n",
    "    if 16 <= hour < 18: return time_of_day_map[\"Late Afternoon\"]\n",
    "    return None\n",
    "\n",
    "# --- Phase 2 Simulation Loop ---\n",
    "print(\"Starting Phase 2: Real-time estimation simulation...\")\n",
    "start_process_time = time.time()\n",
    "results = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "\n",
    "for index, row in flight_gdf.iterrows():\n",
    "    current_time = row['timestamp_utc']\n",
    "    current_easting = row['easting_grid']\n",
    "    current_northing = row['northing_grid']\n",
    "    current_battery = row['battery_percent'] # Assumed column name\n",
    "\n",
    "    season_idx = get_season_idx(current_time.month)\n",
    "    tod_idx = get_tod_idx(current_time.hour)\n",
    "\n",
    "    # Skip if outside valid time context for thermals\n",
    "    if season_idx is None or tod_idx is None:\n",
    "        results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False})\n",
    "        continue\n",
    "\n",
    "    # Define Area of Interest (AOI) bounds around current location\n",
    "    min_x_aoi = current_easting - AOI_SIZE_Meters\n",
    "    max_x_aoi = current_easting + AOI_SIZE_Meters\n",
    "    min_y_aoi = current_northing - AOI_SIZE_Meters\n",
    "    max_y_aoi = current_northing + AOI_SIZE_Meters\n",
    "\n",
    "    # Convert AOI bounds to grid indices\n",
    "    # Use rasterio rowcol, ensuring we get indices relative to the *grid* affine\n",
    "    try:\n",
    "        row_min_aoi, col_min_aoi = rasterio.transform.rowcol(grid_affine, min_x_aoi, max_y_aoi) # Top-left\n",
    "        row_max_aoi, col_max_aoi = rasterio.transform.rowcol(grid_affine, max_x_aoi, min_y_aoi) # Bottom-right\n",
    "\n",
    "        # Clamp indices to grid boundaries\n",
    "        row_min_aoi = max(0, row_min_aoi)\n",
    "        col_min_aoi = max(0, col_min_aoi)\n",
    "        row_max_aoi = min(grid_height - 1, row_max_aoi)\n",
    "        col_max_aoi = min(grid_width - 1, col_max_aoi)\n",
    "\n",
    "        # Check if AOI is valid\n",
    "        if row_min_aoi > row_max_aoi or col_min_aoi > col_max_aoi:\n",
    "             results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": \"Invalid AOI\"})\n",
    "             continue\n",
    "\n",
    "    except IndexError: # UAV outside grid defined by metadata\n",
    "        results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": \"Outside defined grid\"})\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": f\"AOI Index Error: {e}\"})\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Extract data for the AOI\n",
    "    aoi_rows = slice(row_min_aoi, row_max_aoi + 1)\n",
    "    aoi_cols = slice(col_min_aoi, col_max_aoi + 1)\n",
    "\n",
    "    # Sample land cover for each cell in AOI (approximation: sample center)\n",
    "    # This could be slow if AOI is very large - consider optimization if needed\n",
    "    local_probs = np.zeros((row_max_aoi - row_min_aoi + 1, col_max_aoi - col_min_aoi + 1), dtype=np.float32)\n",
    "    aoi_coords_x = []\n",
    "    aoi_coords_y = []\n",
    "    aoi_indices_map = {} # Map flat index to (r, c) relative to AOI\n",
    "\n",
    "    for r_local, r_global in enumerate(range(row_min_aoi, row_max_aoi + 1)):\n",
    "         for c_local, c_global in enumerate(range(col_min_aoi, col_max_aoi + 1)):\n",
    "             # Get center coordinate of the grid cell\n",
    "             cell_center_x, cell_center_y = grid_affine * (c_global + 0.5, r_global + 0.5)\n",
    "             try:\n",
    "                 # Sample land cover raster at cell center\n",
    "                 lc_code_gen = lc_raster.sample([(cell_center_x, cell_center_y)], indexes=1)\n",
    "                 lc_code = next(lc_code_gen)[0]\n",
    "                 if lc_code == lc_raster.nodata: lc_code = 0\n",
    "             except IndexError: lc_code = 0 # Outside raster coverage, treat as NoData\n",
    "             except Exception: lc_code = 0 # Other errors, treat as NoData\n",
    "\n",
    "             lc_idx = lc_code_to_idx_map.get(lc_code)\n",
    "\n",
    "             if lc_idx is not None:\n",
    "                 try:\n",
    "                     prob = prob_map[r_global, c_global, season_idx, tod_idx, lc_idx]\n",
    "                     local_probs[r_local, c_local] = prob\n",
    "                     # Store coords and mapping for sampling\n",
    "                     aoi_coords_x.append(cell_center_x)\n",
    "                     aoi_coords_y.append(cell_center_y)\n",
    "                     aoi_indices_map[len(aoi_coords_x)-1] = (r_local, c_local)\n",
    "                 except IndexError:\n",
    "                     local_probs[r_local, c_local] = 0 # Index out of bounds for prob map\n",
    "             else:\n",
    "                 local_probs[r_local, c_local] = 0 # Invalid LC index\n",
    "\n",
    "    # Normalize probabilities in AOI for sampling\n",
    "    prob_sum = local_probs.sum()\n",
    "    if prob_sum > 1e-9: # Avoid division by zero\n",
    "        sampling_weights = local_probs.flatten() / prob_sum\n",
    "    else:\n",
    "        # If all probabilities are zero/tiny, cannot sample meaningfully\n",
    "        results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"comment\": \"Zero probability in AOI\"})\n",
    "        continue\n",
    "\n",
    "    # Biased Monte Carlo Sampling\n",
    "    # Create flat list of indices corresponding to flattened weights\n",
    "    flat_indices = list(range(len(sampling_weights)))\n",
    "    try:\n",
    "        # Sample ONE flat index based on weights\n",
    "        chosen_flat_idx = np.random.choice(flat_indices, size=1, p=sampling_weights)[0]\n",
    "        # Map flat index back to relative (r_local, c_local) and then get global coords\n",
    "        r_chosen_local, c_chosen_local = aoi_indices_map[chosen_flat_idx]\n",
    "        r_chosen_global = row_min_aoi + r_chosen_local\n",
    "        c_chosen_global = col_min_aoi + c_chosen_local\n",
    "        # Use center of the chosen cell as the estimated location\n",
    "        est_thermal_x, est_thermal_y = grid_affine * (c_chosen_global + 0.5, r_chosen_global + 0.5)\n",
    "\n",
    "    except ValueError as e: # Can happen if weights don't sum to 1 due to precision\n",
    "         results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": f\"MC Sample Error: {e}\"})\n",
    "         continue\n",
    "    except Exception as e:\n",
    "         results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": f\"Unexpected MC Error: {e}\"})\n",
    "         continue\n",
    "\n",
    "\n",
    "    # Get context for the CHOSEN location\n",
    "    try:\n",
    "        final_lc_code_gen = lc_raster.sample([(est_thermal_x, est_thermal_y)], indexes=1)\n",
    "        final_lc_code = next(final_lc_code_gen)[0]\n",
    "        if final_lc_code == lc_raster.nodata: final_lc_code = 0\n",
    "        final_lc_idx = lc_code_to_idx_map.get(final_lc_code)\n",
    "        if final_lc_idx is None: raise ValueError(\"Invalid LC Index\") # Should not happen if map is consistent\n",
    "\n",
    "        final_indices = (r_chosen_global, c_chosen_global, season_idx, tod_idx, final_lc_idx)\n",
    "        final_prob = prob_map[final_indices]\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append({\"timestamp_utc\": current_time, \"thermal_detected\": False, \"error\": f\"Final Context Error: {e}\"})\n",
    "        continue\n",
    "\n",
    "    # Decision Logic\n",
    "    thermal_detected = False\n",
    "    avg_metrics = {}\n",
    "    needs_energy = current_battery < ENERGY_NEED_THRESHOLD\n",
    "\n",
    "    if needs_energy and final_prob > PROBABILITY_THRESHOLD:\n",
    "        thermal_detected = True\n",
    "        try:\n",
    "            avg_metrics = {\n",
    "                \"avg_lift_mps\": avg_metrics_data['avg_lift'][final_indices],\n",
    "                \"avg_radius_m\": avg_metrics_data['avg_radius'][final_indices],\n",
    "                \"avg_height_m_agl\": avg_metrics_data['avg_height'][final_indices],\n",
    "                \"avg_duration_min\": avg_metrics_data['avg_duration'][final_indices]\n",
    "            }\n",
    "            # Replace NaNs with None or 0? Let's use None for clarity\n",
    "            for k, v in avg_metrics.items():\n",
    "                 if np.isnan(v): avg_metrics[k] = None\n",
    "\n",
    "        except IndexError:\n",
    "             thermal_detected = False # Error looking up metrics\n",
    "             avg_metrics = {\"error\": \"Metrics lookup failed\"}\n",
    "        except Exception as e:\n",
    "             thermal_detected = False\n",
    "             avg_metrics = {\"error\": f\"Metrics lookup error: {e}\"}\n",
    "\n",
    "    # Store results for this timestep\n",
    "    result_row = {\n",
    "        \"timestamp_utc\": current_time,\n",
    "        \"uav_lat\": row['latitude'],\n",
    "        \"uav_lon\": row['longitude'],\n",
    "        \"uav_alt_msl\": row['altitude_msl'], # Assumed column name\n",
    "        \"uav_battery_percent\": current_battery,\n",
    "        \"needs_energy\": needs_energy,\n",
    "        \"est_thermal_prob\": final_prob,\n",
    "        \"prob_threshold\": PROBABILITY_THRESHOLD,\n",
    "        \"thermal_detected\": thermal_detected,\n",
    "        \"est_thermal_easting\": est_thermal_x if thermal_detected else None,\n",
    "        \"est_thermal_northing\": est_thermal_y if thermal_detected else None,\n",
    "    }\n",
    "    if thermal_detected:\n",
    "        result_row.update(avg_metrics)\n",
    "\n",
    "    results.append(result_row)\n",
    "\n",
    "\n",
    "print(f\"Finished processing {len(flight_df)} flight data points.\")\n",
    "end_process_time = time.time()\n",
    "print(f\"Processing took {end_process_time - start_process_time:.2f} seconds.\")\n",
    "\n",
    "# --- Save Output CSV ---\n",
    "if results:\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_CSV_FILENAME)\n",
    "    print(f\"Saving estimation results to: {output_path}\")\n",
    "    try:\n",
    "        output_df.to_csv(output_path, index=False, float_format='%.6g')\n",
    "        print(\"Save successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output CSV: {e}\")\n",
    "else:\n",
    "    print(\"No results generated.\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "lc_raster.close()\n",
    "warnings.resetwarnings()\n",
    "print(\"Script finished.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
