{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/px4_sitl/ets_work/montreal_research/venv_montreal/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic thermal data generation with land cover bias...\n",
      "Reading GeoJSON from: /home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/montreal_government_data/df.geojson\n",
      "Using Land Cover from: /home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/montreal_government_data/landcover-2020-classification.tif\n",
      "Source GeoJSON CRS identified as: EPSG:32188\n",
      "Loading Land Cover data...\n",
      "Land Cover CRS identified as: EPSG:3979\n",
      "CRS mismatch detected. Will transform points from EPSG:32188 to EPSG:3979 for sampling.\n",
      "Target includes all 34 regions found in GeoJSON.\n",
      "Total area: 619200849.51 square units (in source GeoJSON CRS units)\n",
      "Generating approximately 30000 thermals...\n",
      "  Generated 1000/30000 thermals...\n",
      "  Generated 2000/30000 thermals...\n",
      "  Generated 3000/30000 thermals...\n",
      "  Generated 4000/30000 thermals...\n",
      "  Generated 5000/30000 thermals...\n",
      "  Generated 6000/30000 thermals...\n",
      "  Generated 7000/30000 thermals...\n",
      "  Generated 8000/30000 thermals...\n",
      "  Generated 9000/30000 thermals...\n",
      "  Generated 10000/30000 thermals...\n",
      "  Generated 11000/30000 thermals...\n",
      "  Generated 12000/30000 thermals...\n",
      "  Generated 13000/30000 thermals...\n",
      "  Generated 14000/30000 thermals...\n",
      "  Generated 15000/30000 thermals...\n",
      "  Generated 16000/30000 thermals...\n",
      "  Generated 17000/30000 thermals...\n",
      "  Generated 18000/30000 thermals...\n",
      "  Generated 19000/30000 thermals...\n",
      "  Generated 20000/30000 thermals...\n",
      "  Generated 21000/30000 thermals...\n",
      "  Generated 22000/30000 thermals...\n",
      "  Generated 23000/30000 thermals...\n",
      "  Generated 24000/30000 thermals...\n",
      "  Generated 25000/30000 thermals...\n",
      "  Generated 26000/30000 thermals...\n",
      "  Generated 27000/30000 thermals...\n",
      "  Generated 28000/30000 thermals...\n",
      "  Generated 29000/30000 thermals...\n",
      "  Generated 30000/30000 thermals...\n",
      "\n",
      "Saving 30000 generated thermals to: /home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/synthetic_generated_data/synthetic_thermal_data_5yr_landcover.csv\n",
      "Save successful.\n",
      "Script finished in 43.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import transform as shapely_transform\n",
    "import pyproj\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import rasterio\n",
    "import warnings\n",
    "\n",
    "GEOJSON_PATH = r\"/home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/montreal_government_data/df.geojson\"\n",
    "LAND_COVER_PATH = r\"/home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/montreal_government_data/landcover-2020-classification.tif\"\n",
    "OUTPUT_FOLDER = r\"/home/px4_sitl/ets_work/montreal_research/thermal_synthetic_data_generation/synthetic_generated_data\"\n",
    "OUTPUT_FILENAME = \"synthetic_thermal_data_5yr_landcover.csv\"\n",
    "\n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(days=5*365)\n",
    "total_seconds_in_period = (end_time - start_time).total_seconds()\n",
    "\n",
    "thermal_months = [5, 6, 7, 8, 9]\n",
    "min_thermal_hour = 10\n",
    "max_thermal_hour = 18\n",
    "\n",
    "thermal_categories = {\n",
    "    \"Weak\": ([0.5, 1.5], [50, 150], [300, 1000], [5, 15], 0.4),\n",
    "    \"Medium\": ([1.5, 3.0], [100, 300], [800, 2000], [10, 30], 0.35),\n",
    "    \"Strong\": ([3.0, 5.0], [150, 400], [1500, 3000], [15, 45], 0.2),\n",
    "    \"Very Strong\": ([5.0, 7.0], [150, 500], [2000, 4000], [20, 60], 0.05)\n",
    "}\n",
    "category_names = list(thermal_categories.keys())\n",
    "category_weights = [thermal_categories[cat][4] for cat in category_names]\n",
    "\n",
    "# --- Land Cover Mapping (Code to Name & Probability) ---\n",
    "# !! IMPORTANT: Verify and complete this based on the XML metadata descriptions !!\n",
    "land_cover_names = {\n",
    "    1: \"Needleleaf Forest\",\n",
    "    2: \"Taiga Forest\",\n",
    "    # 3: \"Missing Category 3\", # Check XML if code 3 exists and add name\n",
    "    5: \"Broadleaf Forest\",\n",
    "    6: \"Mixed Forest\",\n",
    "    8: \"Shrubland\",\n",
    "    10: \"Grassland\",\n",
    "    11: \"Shrubland-Lichen-Moss\",\n",
    "    12: \"Grassland-Lichen-Moss\",\n",
    "    13: \"Barren-Lichen-Moss\",\n",
    "    14: \"Wetland\",\n",
    "    15: \"Cropland\",\n",
    "    16: \"Barren lands\",\n",
    "    17: \"Urban\",\n",
    "    18: \"Water\",\n",
    "    19: \"Snow/Ice\",\n",
    "    0: \"NoData\", # Handle NoData value\n",
    "    'default': \"Unknown\" # Fallback for unexpected codes\n",
    "}\n",
    "\n",
    "land_cover_probabilities = {\n",
    "    1: 0.20, 2: 0.20, 5: 0.25, 6: 0.22, 8: 0.40, 10: 0.50,\n",
    "    11: 0.30, 12: 0.40, 13: 0.35, 14: 0.10, 15: 0.70, 16: 0.75,\n",
    "    17: 0.85, 18: 0.01, 19: 0.00, 0: 0.00, 'default': 0.1\n",
    "}\n",
    "\n",
    "approx_active_hours = 5 * len(thermal_months) * 30 * (max_thermal_hour - min_thermal_hour)\n",
    "thermals_per_active_hour_avg_density = 5\n",
    "total_thermals_to_generate = approx_active_hours * thermals_per_active_hour_avg_density\n",
    "\n",
    "MIN_DIST_FACTOR = 3.0\n",
    "RECENT_POINTS_CHECK = 50\n",
    "MAX_SPATIAL_ATTEMPTS = 200\n",
    "MAX_TIMESTAMP_ATTEMPTS = 100\n",
    "\n",
    "def get_random_point_in_polygon(poly):\n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    while True:\n",
    "        random_point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n",
    "        if poly.contains(random_point):\n",
    "            return random_point\n",
    "\n",
    "def sample_thermal_properties(category):\n",
    "    props = thermal_categories[category]\n",
    "    lift = random.uniform(props[0][0], props[0][1])\n",
    "    diameter = random.uniform(props[1][0], props[1][1])\n",
    "    height = random.uniform(props[2][0], props[2][1])\n",
    "    duration = random.uniform(props[3][0], props[3][1])\n",
    "    return lift, diameter, height, duration\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [6, 7, 8]: return \"Summer\"\n",
    "    if month in [5, 9]: return \"Spring/Fall\"\n",
    "    return \"Off-Season\"\n",
    "\n",
    "def get_time_of_day(hour):\n",
    "    if 10 <= hour < 12: return \"Morning\"\n",
    "    if 12 <= hour < 16: return \"Afternoon\"\n",
    "    if 16 <= hour < 18: return \"Late Afternoon\"\n",
    "    return \"Off-Hours\"\n",
    "\n",
    "print(f\"Starting synthetic thermal data generation with land cover bias...\")\n",
    "print(f\"Reading GeoJSON from: {GEOJSON_PATH}\")\n",
    "print(f\"Using Land Cover from: {LAND_COVER_PATH}\")\n",
    "\n",
    "try:\n",
    "    gdf = gpd.read_file(GEOJSON_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading GeoJSON file: {e}\")\n",
    "    exit()\n",
    "\n",
    "source_crs_geojson = gdf.crs\n",
    "if source_crs_geojson is None:\n",
    "     source_crs_geojson = \"EPSG:32188\"\n",
    "     print(f\"Warning: GeoJSON CRS not set. Assuming {source_crs_geojson}.\")\n",
    "     gdf.crs = source_crs_geojson\n",
    "else:\n",
    "     print(f\"Source GeoJSON CRS identified as: {source_crs_geojson}\")\n",
    "\n",
    "target_crs_latlon = \"EPSG:4326\"\n",
    "\n",
    "print(f\"Loading Land Cover data...\")\n",
    "try:\n",
    "    land_cover_dataset = rasterio.open(LAND_COVER_PATH)\n",
    "    source_crs_raster = land_cover_dataset.crs\n",
    "    print(f\"Land Cover CRS identified as: {source_crs_raster}\")\n",
    "    if source_crs_raster != source_crs_geojson:\n",
    "         print(f\"CRS mismatch detected. Will transform points from {source_crs_geojson} to {source_crs_raster} for sampling.\")\n",
    "         project_coords = pyproj.Transformer.from_crs(source_crs_geojson, source_crs_raster, always_xy=True).transform\n",
    "    else:\n",
    "         project_coords = None\n",
    "except Exception as e:\n",
    "    print(f\"Error opening land cover file {LAND_COVER_PATH}: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Target includes all {len(gdf)} regions found in GeoJSON.\")\n",
    "total_area = gdf.geometry.area.sum()\n",
    "print(f\"Total area: {total_area:.2f} square units (in source GeoJSON CRS units)\")\n",
    "\n",
    "print(f\"Generating approximately {total_thermals_to_generate} thermals...\")\n",
    "\n",
    "synthetic_data = []\n",
    "generated_points_history = []\n",
    "generated_count = 0\n",
    "start_exec_time = time.time()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "while generated_count < total_thermals_to_generate:\n",
    "    valid_timestamp_found = False\n",
    "    timestamp_attempts = 0\n",
    "    timestamp = None\n",
    "    while not valid_timestamp_found and timestamp_attempts < MAX_TIMESTAMP_ATTEMPTS:\n",
    "        timestamp_attempts += 1\n",
    "        random_second_offset = random.uniform(0, total_seconds_in_period)\n",
    "        timestamp = start_time + timedelta(seconds=random_second_offset)\n",
    "        if timestamp.month in thermal_months and min_thermal_hour <= timestamp.hour < max_thermal_hour:\n",
    "             valid_timestamp_found = True\n",
    "    if not valid_timestamp_found: continue\n",
    "\n",
    "    point_accepted = False\n",
    "    spatial_attempts = 0\n",
    "    point_geojson_crs = None\n",
    "    land_cover_code = None\n",
    "    region_name = None\n",
    "\n",
    "    while not point_accepted and spatial_attempts < MAX_SPATIAL_ATTEMPTS:\n",
    "        spatial_attempts += 1\n",
    "        rand_area_val = random.uniform(0, total_area)\n",
    "        cumulative_area = 0\n",
    "        target_region = None\n",
    "        for index, region in gdf.iterrows():\n",
    "            cumulative_area += region.geometry.area\n",
    "            if rand_area_val <= cumulative_area:\n",
    "                target_region = region\n",
    "                break\n",
    "        if target_region is None: target_region = gdf.iloc[-1]\n",
    "        region_geom = target_region.geometry\n",
    "\n",
    "        point_candidate_geojson_crs = get_random_point_in_polygon(region_geom)\n",
    "\n",
    "        coords_for_sampling = (point_candidate_geojson_crs.x, point_candidate_geojson_crs.y)\n",
    "        if project_coords:\n",
    "            try:\n",
    "                coords_for_sampling = project_coords(point_candidate_geojson_crs.x, point_candidate_geojson_crs.y)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            lc_value_generator = land_cover_dataset.sample([coords_for_sampling], indexes=1)\n",
    "            land_cover_code = next(lc_value_generator)[0]\n",
    "        except IndexError:\n",
    "             land_cover_code = 0\n",
    "        except Exception as e:\n",
    "             land_cover_code = 'error'\n",
    "             continue\n",
    "\n",
    "        if land_cover_code == land_cover_dataset.nodata:\n",
    "             land_cover_code = 0\n",
    "\n",
    "        probability = land_cover_probabilities.get(land_cover_code, land_cover_probabilities.get('default', 0))\n",
    "\n",
    "        if random.random() < probability:\n",
    "            point_geojson_crs = point_candidate_geojson_crs\n",
    "\n",
    "            is_too_close = False\n",
    "            temp_radius_for_check = np.mean(thermal_categories[\"Medium\"][1]) / 2.0\n",
    "            check_against = generated_points_history[-RECENT_POINTS_CHECK:]\n",
    "            for prev_point_geojson_crs, prev_radius in check_against:\n",
    "                 if prev_radius is None or temp_radius_for_check is None: continue\n",
    "                 distance = point_geojson_crs.distance(prev_point_geojson_crs)\n",
    "                 min_allowed_distance = MIN_DIST_FACTOR * prev_radius\n",
    "                 if distance < min_allowed_distance:\n",
    "                     is_too_close = True\n",
    "                     break\n",
    "\n",
    "            if not is_too_close:\n",
    "                 point_accepted = True\n",
    "                 region_name = target_region['NOM']\n",
    "        # else: Point rejected by land cover\n",
    "\n",
    "    if not point_accepted: continue\n",
    "\n",
    "    latitude = None\n",
    "    longitude = None\n",
    "    try:\n",
    "         point_gs = gpd.GeoSeries([point_geojson_crs], crs=source_crs_geojson)\n",
    "         point_latlon = point_gs.to_crs(target_crs_latlon).iloc[0]\n",
    "         latitude = point_latlon.y\n",
    "         longitude = point_latlon.x\n",
    "    except Exception as e:\n",
    "         print(f\"Warning: Lat/Lon conversion failed for point {point_geojson_crs}. Error: {e}\")\n",
    "\n",
    "    category = random.choices(category_names, weights=category_weights, k=1)[0]\n",
    "    lift_mps, diameter_m, max_height_m_agl, duration_min = sample_thermal_properties(category)\n",
    "    radius_m = diameter_m / 2.0\n",
    "    season = get_season(timestamp.month)\n",
    "    time_of_day = get_time_of_day(timestamp.hour)\n",
    "    land_cover_name = land_cover_names.get(land_cover_code, land_cover_names.get('default', \"Unknown\")) # Lookup name\n",
    "\n",
    "    generated_points_history.append((point_geojson_crs, radius_m))\n",
    "    if len(generated_points_history) > RECENT_POINTS_CHECK * 2:\n",
    "         generated_points_history = generated_points_history[-RECENT_POINTS_CHECK:]\n",
    "\n",
    "    synthetic_data.append({\n",
    "        \"timestamp_utc\": timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"easting\": point_geojson_crs.x,\n",
    "        \"northing\": point_geojson_crs.y,\n",
    "        \"region_name\": region_name,\n",
    "        \"season\": season,\n",
    "        \"time_of_day\": time_of_day,\n",
    "        \"land_cover_type\": land_cover_name, # Changed from land_cover_code\n",
    "        \"strength_category\": category,\n",
    "        \"lift_rate_mps\": round(lift_mps, 2),\n",
    "        \"core_diameter_m\": round(diameter_m, 1),\n",
    "        \"radius_m\": round(radius_m, 1),\n",
    "        \"max_height_m_agl\": round(max_height_m_agl),\n",
    "        \"duration_min\": round(duration_min)\n",
    "    })\n",
    "    generated_count += 1\n",
    "\n",
    "    if generated_count % 1000 == 0:\n",
    "        print(f\"  Generated {generated_count}/{total_thermals_to_generate} thermals...\")\n",
    "\n",
    "\n",
    "# --- Close Raster and Save Data ---\n",
    "land_cover_dataset.close()\n",
    "warnings.resetwarnings()\n",
    "\n",
    "output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILENAME)\n",
    "print(f\"\\nSaving {len(synthetic_data)} generated thermals to: {output_path}\")\n",
    "\n",
    "if synthetic_data:\n",
    "    df_output = pd.DataFrame(synthetic_data)\n",
    "    cols_order = [\n",
    "        \"timestamp_utc\", \"latitude\", \"longitude\", \"easting\", \"northing\",\n",
    "        \"region_name\", \"season\", \"time_of_day\", \"land_cover_type\", # Updated column name\n",
    "        \"strength_category\", \"lift_rate_mps\",\n",
    "        \"core_diameter_m\", \"radius_m\", \"max_height_m_agl\", \"duration_min\"\n",
    "    ]\n",
    "    df_output = df_output.reindex(columns=[col for col in cols_order if col in df_output.columns])\n",
    "    try:\n",
    "        df_output.to_csv(output_path, index=False)\n",
    "        print(\"Save successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file: {e}\")\n",
    "else:\n",
    "    print(\"No data generated to save.\")\n",
    "\n",
    "end_exec_time = time.time()\n",
    "print(f\"Script finished in {end_exec_time - start_exec_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_montreal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
